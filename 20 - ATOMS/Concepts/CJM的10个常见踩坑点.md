# 避坑指南: CJM的10个常见踩坑点

**标签**: #CJM #避坑指南 #方法论 #质询中
**来源**: [[MOC - 用户体验地图 (CJM) 方法论]]

---

## 10个常见踩坑点及解决方案

### 1. 角色vs细分：误将"用户角色"当成"用户细分"
**问题描述**: 混淆用户角色和用户细分，导致旅程地图越画越多，无法聚焦。

**错误做法**:
- 为每个用户角色都绘制详细的CJM
- 试图满足所有用户群体的需求
- 地图数量膨胀，难以维护

**✅ 正确做法**: 
- 先聚焦商业核心角色，其他的用"快速旅程"验证
- 识别关键用户群体，集中资源优化核心体验
- 建立用户角色优先级，避免过度分散

### 2. 脑补vs真实：用"我以为"代替真实访谈
**问题描述**: 团队内部讨论代替真实用户调研，基于假设而非数据。

**错误做法**:
- 开会讨论"用户可能会怎么想"
- 基于个人经验判断用户需求
- 缺乏一手用户数据支持

**✅ 正确做法**: 
- 至少打10个用户电话，获取一手信息
- 进行真实的用户访谈和观察
- 用实际数据验证团队假设

### 3. 情绪靠感觉：情绪曲线的打分过于主观
**问题描述**: 情绪评分缺乏客观依据，不同人评分差异很大。

**错误做法**:
- 凭感觉给情绪打分
- 没有统一的评分标准
- 忽略用户反馈中的情绪线索

**✅ 正确做法**: 
- 采用双人独立打分，分差过大时重新对齐数据和访谈记录
- 建立情绪评分标准（如-3到+3分）
- 基于用户语言和行为推断情绪状态

### 4. 一次性vs活文档：做完一次就束之高阁
**问题描述**: CJM成为一次性项目，缺乏持续更新和迭代。

**错误做法**:
- 项目完成后就不再更新
- 数据过时但仍在使用
- 没有建立维护机制

**✅ 正确做法**: 
- 每季度更新核心数据，做成"活体"看板
- 建立定期回顾和更新机制
- 将CJM融入日常产品决策流程

### 5. 只有痛点：只贴痛点，没有对应的机会和证据
**问题描述**: 只识别问题，缺乏解决方案和实施依据。

**错误做法**:
- 只列出用户抱怨和问题
- 没有提供解决方案建议
- 缺乏数据支持和优先级排序

**✅ 正确做法**: 
- 同时附上绿色（机会）和蓝色（证据），方便开发评估
- 为每个痛点提供相应的机会点
- 用数据支持问题的重要性和解决方案的可行性

### 6. 忽视内部用户：只关注外部用户，忘了内部用户痛点
**问题描述**: 只考虑终端用户，忽视内部操作人员的体验。

**错误做法**:
- 只关注外部客户的体验
- 忽略客服、运营等内部用户的痛点
- 没有考虑内部流程的优化

**✅ 正确做法**: 
- 将内部后台的操作也视为旅程的一部分
- 考虑内部用户的体验和效率需求
- 优化内外部用户的全链路体验

### 7. 场景过细：旅程阶段切分得太细，变成"流水账"
**问题描述**: 过度细分用户旅程，失去焦点和洞察力。

**错误做法**:
- 将旅程分成几十个小步骤
- 每个步骤都过于详细
- 难以识别关键节点和问题

**✅ 正确做法**: 
- 保持每个阶段的粒度适中，像一个"镜头"
- 聚焦关键决策点和情绪波动
- 确保每个阶段都有明确的开始和结束

### 8. 先画理想态：一上来就画未来的完美旅程
**问题描述**: 直接设计理想状态，忽视现状分析和差距识别。

**错误做法**:
- 直接设计理想的用户体验
- 忽略当前问题和限制
- 缺乏从现状到理想的路径规划

**✅ 正确做法**: 
- 先画"现状"，再画"未来"，才能找到改进的落差
- 基于真实数据绘制当前状态
- 识别现状与理想的差距，制定改进计划

### 9. 不进Backlog：地图挂在墙上吃灰，没有转化为可执行的任务
**问题描述**: CJM停留在分析阶段，没有转化为具体行动。

**错误做法**:
- CJM完成后就束之高阁
- 没有将洞察转化为产品需求
- 缺乏执行跟踪和效果验证

**✅ 正确做法**: 
- 一周内必须将机会点排入Jira/飞书等项目管理工具
- 建立从洞察到需求的转化机制
- 定期跟踪执行进度和效果

### 10. PPT作画：使用协作性差的工具
**问题描述**: 使用不便于团队协作的工具制作CJM。

**错误做法**:
- 使用PPT或静态图片工具
- 难以进行实时协作和更新
- 缺乏版本控制和评论功能

**✅ 正确做法**: 
- 使用Miro/FigJam等在线白板工具，方便团队远程协作和投票
- 选择支持实时协作的工具
- 建立版本管理和评论反馈机制

---

## 避坑检查清单

### 项目启动前
- [ ] 是否明确了核心用户群体？
- [ ] 是否安排了真实用户访谈？
- [ ] 是否选择了合适的协作工具？

### 项目进行中
- [ ] 是否基于真实数据而非假设？
- [ ] 是否建立了客观的评分标准？
- [ ] 是否保持了适当的粒度？

### 项目完成后
- [ ] 是否将洞察转化为具体行动？
- [ ] 是否建立了定期更新机制？
- [ ] 是否获得了团队共识和认可？

---

## 质询与思辨

> [!question] 方法论质疑
> - 这些避坑指南是否过于理想化？在实际项目中，资源和时间限制往往让我们无法做到"完美"，如何在现实约束下做出最佳权衡？

> [!question] 适用性问题
> - 不同类型的公司（初创vs大企业）、不同类型的产品（C端vsB端），这些避坑点的优先级是否应该调整？
- 在快速迭代的环境中，某些"最佳实践"可能会拖慢进度，如何平衡质量和效率？

> [!idea] 实践思考
- 可以考虑建立"CJM成熟度模型"，根据团队和项目的实际情况，分阶段实施这些最佳实践
- 对于关键项目严格遵循所有避坑指南，对于小型项目可以适当简化流程
- 建立团队内部的CJM经验分享机制，持续学习和改进

---

## 相关工具

- [[CJM的核心骨架：时间轴 x 5层信息]] - 基础框架
- [[CJM速成法：48小时突击流程]] - 快速实施方法
- [[CJM案例研究：电影票小程序转化率优化]] - 实际案例