# MOC: LLM如何理解文字 - 从文本到向量

**核心启发来源**: [[LLM如何理解文字 - 词汇表映射深度解析]]
**核心思想**: 计算机无法直接处理文字，必须通过一系列步骤，将人类的语言（文本）转化为机器能够理解和计算的、蕴含丰富语义信息的数字（向量）。

---

### 文本处理的四步流程

1.  **拆分 (Splitting)**: [[分词 (Tokenization)]]
    - *将连续的文本字符串，拆解成有意义的最小单元 (Token)。*

2.  **编码 (Encoding)**: [[词汇表映射 (Vocabulary Mapping)]]
    - *为每一个Token分配一个独一无二的数字ID。*

3.  **表示 (Representation)**: [[词嵌入 (Word Embedding)]]
    - *将数字ID转换为高维向量，让数字拥有"意义"。*

4.  **理解 (Understanding)**: [[模型处理 (Model Processing)]]
    - *通过分析向量之间的关系，理解上下文和深层语义。*

### 核心类比
- [[乐高积木比喻：理解Token与ID]]

---

### 相关项目与学习

**关联项目**: [[AI大模型学习体系/MOC - AI大模型学习路径]]
**学习目标**: 理解LLM的基础工作原理，为产品设计和决策提供技术洞察

### 关键问题清单

- 分词粒度如何影响模型性能？
- 词汇表大小对产品的影响是什么？
- 词嵌入的维度如何选择？
- 模型的"理解"与人类理解的本质区别？
- 如何处理未登录词问题？

### 动态查询

```dataview
TABLE 文件链接 AS "相关笔记", 标签 AS "分类"
FROM #技术概念/NLP OR #隐喻/AI
WHERE contains(文件链接, "LLM") OR contains(文件链接, "Token") OR contains(文件链接, "Embedding")
SORT 文件链接
```

### 进度跟踪

**学习状态**: #质询中  
**最后更新**: <% tp.date.now("YYYY-MM-DD") %>  
**下次回顾**: <% tp.date.now("YYYY-MM-DD", 7) %>